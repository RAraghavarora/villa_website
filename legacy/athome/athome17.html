
<h1>UT Austin Villa</h1>
<h1>RoboCup@Home DSPL Team</h1>
<center>
    <ul class="year-choice">
        <li><a href="https://www.cs.utexas.edu/~AustinVilla/?p=athome/athome22"> 2022</a></li>
        <li><a href="https://www.cs.utexas.edu/~AustinVilla/?p=athome/athome21"> 2021</a></li>
        <li><a href="https://www.cs.utexas.edu/~AustinVilla/?p=athome/athome20"> 2020</a></li>
        <li><a href="https://www.cs.utexas.edu/~AustinVilla/?p=athome/athome19"> 2019</a></li>
        <li><a href="https://www.cs.utexas.edu/~AustinVilla/?p=athome/athome18"> 2018</a></li>
        <li><a href="https://www.cs.utexas.edu/~AustinVilla/?p=athome/athome17"> 2017</a></li>
        <li><a href="https://www.cs.utexas.edu/~AustinVilla/?p=athome/athome07"> 2007</a></li>
    </ul>
</center>
<hr>
<h2>Professors Peter Stone, Andrea Thomaz, Scott Niekum, Luis Sentis, Raymond J. Mooney, and Justin W. Hart</h2>
<h2>The University of Texas at Austin</h2>

<hr/>

<h3> Description of the approach and information on scientific achievements</h3>

<p>Profs. Stone, Thomaz, and Niekum aim to combine their expertise in
reinforcement learning, human-robot interaction, and learning from
demonstration towards a full solution to the RoboCup@Home challenge.
We propose to bring together postdocs, graduate students, and
undergraduate students from each of our groups to enable the HSR robot
to interact seemlessly with people in the environment, learn behaviors
ranging from object manipulation to robust environmental perception,
to high-level task sequencing.  Our development efforts will be
situated within our ongoing <a
href="http://www.cs.utexas.edu/~larg/bwi_web/">Building-Wide
Intelligence project</a>, which already includes several
human-interactive robots, and which has the long-term objective of
enabling a team of robots to achieve long-term autonomy within the
rich socially interactive environment of the UT Austin Computer
Science building.  The HSR robot will thus be embedded within a
multi-robot system of heterogeneous robots while its novel software is
under development at UT Austin (though of course during the
    competition it will act fully independently).</p>

<p>Profs. Thomaz and Niekum have performed much of their past research in
home-like environments and have an existing shared lab space set up as
an apartment with a living room, dining room, and kitchen.  This lab
space is in the same building as the Building-Wide Intelligence, and
will therefore allow us to easily develop and test the robot in both
an open, fully interactive setting and a more controlled home-like
    setting.</p>
<center>
<div class="imgboxrt">
<img
src="http://www.cs.utexas.edu/~AustinVilla/athome/HSRProposal2016/UT-Poli-collage.jpg" alt="UT Poli collage"/>
<div class="caption">Profs. Thomaz' and Niekum's lab</div>
</div>
</center>


<p>
We expect the HSR robot to enhance our overall system's breach of
capabilities and thus quickly play an important role in novel research
on topics ranging from activity recognition, to robust perception, to
learned planning and navigation, to general human-robot interaction.
Throughout our development, we will continue our strong tradition of
releasing well-documented, self-contained behavior modules for
components of autonomous robots that can be used by other research
groups to enhance their own research.
<p>

The team leaders' past scientific achievements are chronicled on their
respective websites:
<ul>
   <li> <a href="http://www.cs.utexas.edu/~pstone/">Peter Stone</a></li>
   <li> <a href="http://www.ece.utexas.edu/people/faculty/andrea-thomaz">Andrea Thomaz</a></li>
   <li> <a href="http://www.cs.utexas.edu/~sniekum/">Scott Niekum</a></li>
</ul>


<hr>

<h3> Relevant publications</h3>

<ul>
   <li> UT Austin Villa's <a href="http://www.cs.utexas.edu/~AustinVilla/?p=papers">RoboCup-related
      papers</a> (from Prof. Stone's group).</li>
   <li> Relevant publications from the <a href="http://www.cs.utexas.edu/~larg/bwi_web/publications/">Building-Wide Intelligence
   (BWI) project</a>.
   
   <li> Prof. Niekum's relevant publications on manipulation and learning from demonstration
   <ul>
      <li>S. Niekum, S. Osentoski, C.G. Atkeson, and A.G. Barto.<br/>
<a href="http://www.cs.utexas.edu/users/sniekum/pubs/CPD15.pdf" rel="self">Online Bayesian Changepoint Detection for Articulated Motion Models</a>.<br/>
         IEEE International Conference on Robotics and Automation (ICRA), May 2015. </li>

<li>K. Hausman, S. Niekum, S. Osentoski, and G. Sukhatme. <br/>
<a href="http://www.cs.utexas.edu/users/sniekum/pubs/active15.pdf" rel="self">Active Articulation Model Estimation through Interactive Perception</a>.<br/>
   IEEE International Conference on Robotics and Automation (ICRA), May 2015.</li>

<li>S. Niekum, S. Osentoski, G.D. Konidaris, S. Chitta, B. Marthi, and A.G. Barto. <br/>
<a href="http://ijr.sagepub.com/content/34/2/131.abstract" rel="self">Learning Grounded Finite-State Representations
from Unstructured Demonstrations</a>.<br/>
   International Journal of Robotics Research (IJRR), Vol. 34(2), pages 131-157, February 2015.  </li>

<li>S. Niekum, S. Osentoski, S. Chitta, B. Marthi, and Andrew G. Barto.<br/>
<a href="http://www.cs.utexas.edu/users/sniekum/pubs/NiekumRSS2013.pdf" rel="self">Incremental Semantically Grounded Learning from Demonstration</a>. <br/>
   Robotics: Science and Systems 9 (RSS), June 2013.</li>

<li>S. Niekum, S. Osentoski, G.D. Konidaris, and Andrew G. Barto.<br/>
<a href="http://www.cs.utexas.edu/users/sniekum/pubs/NiekumIROS2012.pdf" rel="self">Learning and Generalization of Complex Tasks from Unstructured
Demonstrations</a>.<br/>
   IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 5239-5246, October 2012.</li>
</ul>
</li>

<li> Prof. Thomaz' relevant publications on human-robot interaction.
   <ul>
      <li>V Chu, B Akgun, AL Thomaz.<br/>
      <a href="http://ieeexplore.ieee.org/document/7463165/">Learning haptic affordances from demonstration and human-guided exploration</a><br/>
         IEEE Haptics Symposium (HAPTICS), 2016</li>
      
      <li>Crystal Chao, Andrea Thomaz.<br/>
      <a href="http://ijr.sagepub.com/content/early/2016/03/09/0278364915627291.abstract">
      Timed Petri nets for fluent turn-taking over multimodal interaction resources in human-robot collaboration.</a><br/>
         IJRR 35(11): 1330-1353 (2016)</li>
      
      <li>B Akgun, A Thomaz</br>
      <a href="http://link.springer.com/article/10.1007/s10514-015-9448-x">Simultaneously learning actions and goals from demonstration</a><br/>
         Autonomous Robots, 2016</li>
      
      <li>B Akgun, AL Thomaz<br/>
      <a href="http://ieeexplore.ieee.org/abstract/document/7354119/">
      Self-improvement of learned action models with learned goal models</a><br/>
         IEEE/RSJ International Conference on Robots and Systems (IROS), 2015</li>
      
      <li>V Chu, T Fitzgerald, AL Thomaz <br/>
      <a href="http://dl.acm.org/citation.cfm?id=2906869">
      Learning Object Affordances by Leveraging the Combination of Human-Guidance and Self-Exploration</a><br/>
         The Eleventh ACM/IEEE International Conference on Human Robot Interaction, 2015 </li>
      
      <li>Sonia Chernova and Andrea L. Thomaz.<br/>
      <a href="http://www.morganclaypool.com/doi/abs/10.2200/S00568ED1V01Y201402AIM028?journalCode=aim">
      Robot learning from human teachers.</a> <br/>
         Synthesis Lectures on Artificial Intelligence and Machine Learning, 8(3):1 121, 2014.</li>
   </ul>
</li>
</ul>

<hr/>

<h3> Relevant photos/videos</h3>

<ul>
    <li>Our <a href="https://drive.google.com/file/d/0B10UkB-gUiRuX2YwSUR3dGl0T00/view?usp=sharing">qualification video</a> and the all <a href="https://drive.google.com/drive/folders/0B561ftgmvJkAMnFuaWRPUEpJUTQ?usp=sharing">unedited clips</a></li>
<li> Videos from our past participation in RoboCup@Home are available
at the bottom of our <a
href="http://www.cs.utexas.edu/~AustinVilla/?p=athome">RoboCup@Home
        page</a>.
    <ul>
       <li> A <a
       href="http://www.cs.utexas.edu/~AustinVilla/athome/UT_ICRA_Video.mpeg">narrated video</a> was presented at ICRA 2008.
    </ul>
</li>
<li> There are many other videos from our compeitions available on the
UT Austin Villa <a href="http://www.cs.utexas.edu/~AustinVilla/?p=competitions"> 
        competitions page.</a></li>

<li> There are several <a href="http://www.cs.utexas.edu/~AustinVilla/?p=research">research
    videos associated with papers relevant to our RoboCup team</a></li>
    <li> There are several <a href="http://www.cs.utexas.edu/~larg/bwi_web/publications/">research videos associated with papers relevant to the BWI project</a></li>
    <li> Videos of the BWI project at <a href="http://www.cs.utexas.edu/~larg/bwi_web/outreach/">outreach events</a></li>

<li> Video of Prof. Niekum's research on <a href="https://www.youtube.com/watch?v=oIbfhHRt9AA">autonomous IKEA
    furniture assembly</a></li>

    <li> TEDx overview of Prof. Thomaz' research on <a href="https://www.youtube.com/watch?v=O1ZhWv84eWE">socially collaborative robots</a></li>

<li> Prof. Thomaz' research on <a href="https://www.youtube.com/watch?v=S1wXI35GG7k">Embodied Active Learning
    Queries</a></li>
<li> Prof. Thomaz' research on <a href="https://www.youtube.com/watch?v=Gx3_W6GI7eY">Multimodal turn-taking
    collaborations</a></li>
</ul>

<hr/>

<h3> Software</h3>

<p>During our participation in the RoboCup@Home SPL, we are fully
committed to continuing our strong tradition of contributing open
   source code to the community.</p>


<ul>
<li> Our <a
href="http://www.cs.utexas.edu/~pstone/Papers/bib2html/b2hd-LNAI16-MacAlpine2.html">
UT Austin Villa RoboCup 3D Simulation Base Code Release</a> won 2nd
prize in the 2016 Harting Open Source Competition.  It is the basis for our team that has won 5 of the 6 competitions. 

<li> Our <a
href="http://www.cs.utexas.edu/~pstone/Papers/bib2html/b2hd-LNAI13-Barrett.html">Soccer
SPL source code release</a>, which formed the core of our 2012
SPL championship, has been widely used in the league.

<li> Our <a href="https://github.com/utexas-bwi/">BWI code
repository</a> provides an open source suite of ROS packages, fully
integrated into an architecture for service robots that operate in
dynamic and unstructured human-inhabited environments.  It has been
built on top of the Robot Operating System (ROS) middleware
framework. This software architecture provides a hierarchical layered
approach for controlling autonomous robots, where layers in the
hierarchy provide different granularities of control.  Specifically,
this architecture includes navigation software that allows a mobile
robot to move autonomous inside a building, while being able to switch
2D navigational maps when using the elevator to move to a different
floor. A symbolic navigation module is built on top of this autonomous
navigation module which allows the robot to navigate to prespecified
doors, rooms, and objects in the environment.  From a high-level
perspective, the software architecture includes planning and reasoning
modules that allow the robot to execute high level tasks, such as
delivering an object from one part of the building to another, using a
    complex sequence of symbolic actions.</li>


<li> Our <a
href="http://www.cs.utexas.edu/~pstone/Papers/bib2html/b2hd-RoboCup13-hester.html">TEXPLORE
code</a> provides an open-source package for reinforcement learning on
   real robots.</li>

<li> Our <a href="http://wiki.ros.org/ar_track_alvar">ar_track_alvar</a> ROS package has become a community
   standard for tag-based perception.</li>

<li> Our ROS implementation of <a href="http://wiki.ros.org/dmp">Dynamic
   Movement Primitives</a> has become a popular tool for learning from demonstration. </li>

<li> We have made research code available for:
      <ul>
         <li> <a href="http://wiki.ros.org/changepoint">Bayesian changepoint
         detection</a>, </li>
         <li><a href="http://wiki.ros.org/active_articulation">active articulated model estimation</a>,  and</li>
         <li> <a href="http://www.cs.utexas.edu/users/sniekum/code/BPARHMMtoolbox.zip">Bayesian nonparametric skill learning from
            demonstration</a>.</li>
      </ul>
   
   </li>
</ul>

<hr/>

<h3>Team Roster</h3>

<ul>
    <li><a href="http://justinhart.net">Justin Hart</a>, Postdoctoral fellow with the Learning Agents Reserach Group</li>
    <li><a href="http://www.cs.utexas.edu/~jsinapov/">Jivko Sinapov</a>, Post-doctoral fellow with the Learning Agents Research Group</li>
    <li><a href="http://www.cs.utexas.edu/~rf22784/">Rolando Fernadez</a>, Masters student</li>
    <li><a href="https://nickwalker.us">Nick Walker</a>, undgergraduate student</li>
</ul>

<p>Additionally, we will be recruiting students from the <a href="https://cns.utexas.edu/fri">Freshman Research Initiative</a>  <a href="http://www.cs.utexas.edu/~jsinapov/teaching/cs309_spring2017/">Autonomous Intelligent Robotics stream</a>. We expect to add five additional students for the summer in this way.</p>

<hr/>

<h3> Previous participation in RoboCup</h3>



<ul>
<li> UT Austin Villa has participated successfully in <a
href="http://www.cs.utexas.edu/~AustinVilla/?p=competitions"> past
RoboCup competitions,</a> every year since 2003.
   <ul>
      <li>In 2012, we finished 1st plance in the soccer SPL,</li>
      <li>in 2016, we finished 2nd place in the soccer SPL, </li>
      <li>and also in 2016, we finished 1st place in the 3D simulation league for the 5th time in 6 years.</li>
   </ul>
   </li>

    <li> We finished <a href="http://www.cs.utexas.edu/~AustinVilla/?p=athome">2nd place in RoboCup@Home at RoboCup 2007</a>.</li>
</ul>

<center>
    <div class="imgboxrt">
        <img src="http://www.cs.utexas.edu/~AustinVilla/athome/finalcapture3.jpg" alt="Segway at Robocup @Home 2007"/>
        <div class="caption">Segway in Robocup @Home 2007 Final</div>
    </div>
</center>

